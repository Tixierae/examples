"start" "end" "role" "text"
1 10 "part1" "Bon c'est parti "
2 20 "part2" "on va le mettre là puis On va essayer de l'oublier"
3 30 "part1" "bon Juste pour t'expliquer en fait on refait un peu comme comme hier sauf qu'on chacun détaille un petit peu plus ce qu'il a fait et puis puis on essaye de de discuter puis sur sur des points plus en detail que ce qu'on a ce qu'on a deja discuté hier "
4 40 "part2" "Ilyès au fait tu tu avais pas aussi une une il n'y avait pas une stagaire là qui travaillait avec toi "
5 50 "part1" "oui"
6 60 "part2" " je me souviens plus de de de de son prénom et elle elle continue à travailler avec toi"
7 70 "part1" "oui elle est en train de travailler avec moi "
8 80 "part2" "ok tu tu la parce que ça serait peut-être pas mal si elle participait aussi donc aux réunions et puis qu'on parle aussi de de ce qu'elle fait ouais qu'est-ce-que t'en penses"
9 90 "part1" "ok"
10 100 "part2" "ok donc "
11 110 "part1" "j'ai pas bien entendu"
12 120 "part2" "ah tu comprends pas bien le le son est pas bon la parce que je suis sur le le wifi en fait "
13 130 "part1" "si tu veux on peut non mais il n'y a pas de cable c'est pas assez long ça me parait un peu un peu limite "
14 140 "part2" "non ça va pas être assez long ouais mais si je me mets là bas ça va quand même être un peu bizarre quoi tandis que là hop ouais mais laisse tomber "
15 150 "part1" "tu tu est-ce-que tu entends la c'est c'est c'est haché ou non c'est bien ça va ouais ça va oui donc ce que je disais c'est à propos de de de la stagiaire qui qui travaille avec toi donc t'es sur le sur le modèle en langue arabe ça serait peut être bien qu'elle participe aussi aux réunions "
16 160 "part2" "en fait c'est un jour férié "
17 170 "part1" "ah aujourd'hui"
18 180 "part2" "oui aujourd'hui demain et après demain "
19 190 "part1" "ah d'accord"
20 200 "part2" "c'est l'Eid chez vous"
21 210 "part1" "comment "
22 220 "part2" "c'est l'Eid chez vous"
23 230 "part1" "oui "
24 240 "part2" "c'est aujourd'hui l'Eid "
25 250 "part1" "non c'est demain l'Eid mais c'est un jour férié"
26 260 "part2" "ok d'accord"
27 270 "part1" "ok donc bah tu bon non là je comprends mais donc tu tu es peut être pas du coup Linagora c'est fermé aujourd'hui "
28 280 "part2" "oui oui"
29 290 "part1" "ah ok donc tu es chez toi peut être "
30 300 "part2" "ouai "
31 310 "part1" "ok ok bon mais pour la semaine prochaine peut-être on on pourra la la faire participer"
32 320 "part2" "ouais oui ok"
33 330 "part1" "d'accord"
34 340 "part2" "d'accord"
35 350 "part1" "bon très bien "
36 360 "part2" "bah tu tu pourras lui raconter quand même bah tu t'as qu'à commencer tiens Ilyès et puis tu peux aussi nous nous nous nous parler de ce que tu fais avec elle"
37 370 "part1" "ok en fait au début elle a commencé à faire tourner Kaldi donc je lui demandais d'installer et de lancer un petit un petit exemple pour comprendre de quoi il s'agit comprendre les étapes et comment fonctionne Kaldi"
38 380 "part2" "ensuite je lui donnais la base de langue arabe donc bon son ordinateur n'est pas très puissant donc ça prend beaucoup de temps pour faire l'apprentissage et tous les etapes lancer tous les etapes "
39 390 "part1" "donc je lui demandais de voir d'autres choses par exemple les caractéristiques comment que extrait quelques caractéristiques changer des paramètres défaire des paramètres pour enfin si ça refonctionne sur une petit base voir l'effet de ces paramètres elle peut le lancer par exemple sur la langue arabe ou bien le français etcetera elle a fait ça et maintenant j'ai lui donné la base de langue française pour faire ça pour tester ça donc donc déjà juste je lui ai demandé d'utiliser au lieu d'utiliser  toute la base française donc juste utiliser une partie et faire calculer et changer les paramètres et de jouer sur cette partie pour ensuite un peu alncer ça sur toute la base et voir la performance en changeant les paramètres"
40 400 "part2" "ok et la la base que vous utilisez pour la langue arabe c'est quoi"
41 410 "part1" "c'est une base d'un challenge "
42 420 "part2" "ah oui le challenge du de Al-Jazeera c'est ça"
43 430 "part1" "oui c'est ça"
44 440 "part2" "ok "
45 450 "part1" "et là il y a ya a vraiment du beaucoup de beaucoup de d'informations "
46 460 "part2" "ouais"
47 470 "part1" "combien d'heures"
48 480 "part2" "je sais pas exactement mais c'est cent quarante giga le la taille des données "
49 490 "part1" "donc je pense c'est plus que mille heures "
50 500 "part2" "ah oui ok non mais c'est pour avoir un ordre d'idée hein "
51 510 "part1" "c'est mille deux cent heures"
52 520 "part2" "mille deux cent heures ok "
53 530 "part1" "oui"
54 540 "part2" "avec un grand nombre de locuteurs aussi"
55 550 "part1" "oui un nombre donc dataframe Jazeera "
56 560 "part2" "ouais donc ça c'est c'est intéressant d'avoir pu récupérer ça voilà bon après il va falloir effectivement un ordinateur suffisament puissant pour pour pour pouvoir calculer calculer quoi "
57 570 "part1" "ouais non on arrête on a commandé la commande est partie pour le pour la la la carte GPU enfin le serveur donc le le serveur de calcul donc on devrait on devrait recevoir en petits morceaux hein d'après ce que ce que j'ai compris de de de la commande en fait c'est parti chez Amazon "
58 580 "part2" "c'était rapide au final enfin une fois que "
59 590 "part1" "ah oui oui oui oui c'était rapide oui une fois que une fois que le processus a été enclenché ca a été suffisament rapide j'ai fait la la demande d'achat Michel l'a signé tout de suite et puis et puis Valérie a fait la la commande"
60 600 "part2" "Ben je pense qu'avec la wishlist ça lui a "
61 610 "part1" "facilité"
62 620 "part2" "ça lui a peut être facilité le travail "
63 630 "part1" "c'est sur "
64 640 "part2" "du coup du du coup on devrait recevoir on commence à recevoir des morceaux je crois à la fin de la semaine mais"
65 650 "part1" "ça ça dépend quoi "
66 660 "part2" "ça sera surtout la semaine prochaine "
67 670 "part1" "surtout la semaine prochaine "
68 680 "part2" "bon "
69 690 "part1" "je serais pas là"
70 700 "part2" "oui ah oui du coup t'es pas la ouais donc on recueillera les les morceaux on verra ouais enfin bon faut pas ouais bon il faut peut être attendre de toute manière d'avoir tous les morceaux ah oui c'est tellement mieux pour commencer sinon c'est un jeu de construction on va on va être déçus s'il manque puis s'il manque la le le ventilo ou l'alim bon c'est des pièces quand même s'il manque la carte mère ça va être difficile ouais ouais pour le monter s'il y a tout le reste "
71 710 "part1" "bon en en tout état de cause donc c'est parti mais a mon avis avant qu'on puisse l'utiliser il faut bien il faut bien compter compter deux deux semaines quoi entre le la réception du matériel l'installation l'installation et puis du système si on met deux ou trois semaines ça sera ça sera déjà bien à mon avis "
72 720 "part2" "ok donc donc en tout cas pour pour le pour cette pour cette partie la faudra en tout cas faudra faudra attendre un peu quoi "
73 730 "part1" "ok et donc sinon sur le pour le toi t'as continué à travailler sur la base donc en français "
74 740 "part2" "oui "
75 750 "part1" "ok tu tu peux élaborer un peu"
76 760 "part2" "ok donc j'ai travaillé surtout sur la construction de la base avoir plus de données pour l'apprentissage parce qu'en fait trente heures c'est très négligeable par rapport à ce que les autres utilisent pour faire l'apprentissage même si j'ai utilisé trente heures donc le le test c'est pas très mauvais c'est environ trente trente pourcent quarante pourcent donc et aussi sans changer les paramètres sans utiliser les réseaux de neurones je pense c'est pas très mauvais ce que j'ai obtenu jusqu'à maintenant faut juste on doit juste utiliser plus de données dans l'apprentissage jouer aussi sur les méthodes d'apprentissage les réseaux de neurones les paramètres etcetera je pense qu'on peut obtenir enfin de très bons résultats "
77 770 "part1" "dès lors qu'on aura plus de plus de de de données quoi "
78 780 "part2" "oui oui"
79 790 "part1" "plus de données donc on peut avoir de bons résultats des d'autres bases utilisent cent heures mille heures donc trente heures c'est c'est rien par rapport à les autres modèles des autres langues "
80 800 "part2" "mais du coup tu penses que tu vas réussir à atteindre une base de quelle taille toi à la main en faisant ce que tu fais actuellement "
81 810 "part1" "on peut obtenir ce qu'on peut veut ce qu'on veut mais ça prend du temps "
82 820 "part2" "beh oui"
83 830 "part1" "mais c'est ça le problème oui"
84 840 "part2" "oui c'est ça le problème "
85 850 "part1" "donc le j'ai passé presque un mois environ un mois pour préparer une base de trente heures "
86 860 "part2" "oui du coup "
87 870 "part1" "on peut accélerer ça si on partage ces taches sur plusieurs personnes mais au minimum on peut obtenir une base de cent heures c'est bien si on on obtient en première étape une base de cent heures et tester vraiment la performance et jouer sur tous les paramètres "
88 880 "part2" "ouais vasy attends il y a Jessica qui veut dire quelque chose"
89 890 "part1" "du coup Elyès depuis vendredi tu sais les les fichiers que que j'ai mis sur le le serveur là Mega tu les a inclus dans le corpus ou ou pas"
90 900 "part2" "j'ai pas encore tout utilisé j'ai téléchargé j'ai regardé ok de quoi il s'agit mais "
91 910 "part1" "parce que je les ai j'en ai encore mis ce matin mais du coup quand tu dis préparer les données enfin au dela de juste les récolter t'en fait quoi en fait "
92 920 "part2" "non c'est pas seulement utiliser  comme le format que tu as mis il faut préparer seulement il faut avoir seulement le texte oui il faut filtrer les texte ah oui dans dans ces fichiers donc récupérer seulement le texte ouais prononcé ensuite il faut segmenter ces fichiers parole des segments de dix quinze secondes donc c'est faire ça semi-automatique attends j'utilise un programme automatique pour faire la segmentation des fichiers audio en se basant sur les silences du coup et ensuite je segmente la transcription manuellement c'est ça le problème donc mais pourquoi ça prend du temps tu coupes les fichiers audio en sachant que la plupart ils sont pas super longs "
93 930 "part1" "j'ai pas entendu "
94 940 "part2" "pourquoi tu les coupes enfin il y en a quelques un ils ils sont super longs mais quand ça fait une minute tu gagnes quoi à les segmenter en trucs de dix secondes "
95 950 "part1" "s'il y a beaucoup de texte donc il faut les segmenter "
96 960 "part2" "en fait c'est recommandé d'utiliser des segments d'accord de courte durée "
97 970 "part1" "et c'est combien de de en en gros le la durée de d'un segment"
98 980 "part2" "en général c'est dix quinze secondes j'ai vérifié pour d'autres bases pour l'ang pour l'anglais et j'ai trouvé cinq dix quinze secondes mais en fait pour moi même il y a des segments de trente quarante secondes "
99 990 "part1" "mais ce que je comprends pas c'est c'est du coup tu fais l'apprentisssage sur des des segments super courts et t'es d'accord que dans la vraie utilisation du logiciel qu'on va développer on va pas parler par segments enfin justement le si on segmentait pas peut être ça serait moins précis au début mais ça serait plus  comment dire plus réaliste quoi je sais pas j'avais jamais vu je sais pas "
100 1000 "part2" "mais en fait ce sont des segments une minute segment une minute c'est la même chose de d'un segment de trente ou dix secondes en fait c'est en temps réel  qu'on va faire la reconnaissance "
101 1010 "part1" "ouais ce que en fait quand tu fais la reconnaissance ensuite quand le système derrière il fait la reconnaissance il doit prendre des des des fenêtres ouais d'accord qu'il déplace ouais tu vois il y a une espèce enfin je fenêtre de Hamming ouais voilà"
102 1020 "part2" "ouais voilà et du coup du coup ça doit correspondre à ce à cet intervalle de segmentation quoi ouai"
103 1030 "part1" "ça me semble être énormement de travail en fait de segmenter pour je sais pas enfin fin il y a surement une théorie derrière s'il le fait mais pour un mois pour trente heures de corpus ça me semble énorme quoi "
104 1040 "part2" "ouais ouais au début je sais parce que au début t'avais t'avais essayé sans sans segmenter de mémoire et et alors les résultats étaient extrêmement mauvais d'accord ouais et ça prend du temps pour le décodage"
105 1050 "part1" "c'est pas la même chose le decodage d'un segment d'une minute ou de cinq minutes qu'un segment de dix secondes mais c'est j'ai j'ai cherché sur internet et j'ai trouvé que c'est recommandé d'utiliser des segments d'utiliser des segments de courte durée c'est pour ça j'ai fait ça d'accord "
106 1060 "part2" ""
107 1070 "part1" "d'accord"
108 1080 "part2" "ok et du coup du coup pour faire ça evidemment euh ça veut dire que il faut faut prendre le le le le donc en fait toi ce que tu tu obtiens pour l'instant c'est d'une part le texte"
109 1090 "part1" "ouais"
110 1100 "part2" "d'autre part le euh le le "
111 1110 "part1" "fichier audio "
112 1120 "part2" "fichier mp3 euh et audio "
113 1130 "part1" "ouais en sachant que deja le texte c'est souvent des formats bizarres en fonction de des gens qui ont récoltés les corpus des fois y a des lignes avec des numéros en début enfin vous voyez ce il y a du texte mais aussi "
114 1140 "part2" "des métadonnées quoi"
115 1150 "part1" "ouais voila des trucs inutiles"
116 1160 "part2" "ben ça dépend par exemple ben s'il y a une métadonnée qui indique le temps"
117 1170 "part1" "ouais"
118 1180 "part2" "du coup on peut imaginer segmenter le fichier texte de manière automatique par rapport à comment on a segmenté le fichier audio"
119 1190 "part1" "ouais dès lors qu'on a un outil qui qui sait euh"
120 1200 "part2" "enfin oui ça peut se parser euh si c'est un si c'est un format pas trop compliqué tu peux faire un parter quoi qui va faire ouais la segmentation"
121 1210 "part1" "oui soit tu le fais l'outil soit tu parce que euh il y a peut être des outils qui euh font ça je suis que cette chaîne de de de production auquel on on est euh "
122 1220 "part2" "il faudra voir avec les fichiers de sous-titres "
123 1230 "part1" "confronté"
124 1240 "part2" "parce que c'est le"
125 1250 "part1" "ouais ce genre de truc"
126 1260 "part2" "les gens qui font des sous-titrages de film doivent avoir des trucs "
127 1270 "part1" "il  y a peut-être des standards "
128 1280 "part2" "ouais"
129 1290 "part1" "enfin si ça c'est le pire en fait parce que ça sert à tu vois la y a "
130 1300 "part2" "en fait ça identifie la personne qui parle peut-être"
131 1310 "part1" "peut-être pas"
132 1320 "part2" "ouais genre le texte hotesse client"
133 1330 "part1" "ah ouais même pas"
134 1340 "part2" "ouais d'accord c'est pourri là"
135 1350 "part1" "là c'est même pas du temps et puis des fois il y a le temps mais des fois il y a "
136 1360 "part2" "c'est l'espèce de moment"
137 1370 "part1" "ouais"
138 1380 "part2" "enfin ça ressemble après aux aux métadonnées peut-être que que par exemple euh l'école polytechnique nous a demandé d'inclure "
139 1390 "part1" "peut-être ouais"
140 1400 "part2" "à l'issue de la transcription tu sais à l'issue de la transcription il faut mettre des métadonnées euh le temps euh le la personne "
141 1410 "part1" "ouais c'est "
142 1420 "part2" "la y a les personnes la"
143 1430 "part1" "mais chacun ils ont tous des donéées différentes"
144 1440 "part2" "ouais"
145 1450 "part1" "là juste je change de sujet mais ça me fait penser dans ton rapport tu tu l'as décrit le euh le euh la structure là du du fichier de l'école polytechnique "
146 1460 "part2" "oui"
147 1470 "part1" "ok "
148 1480 "part2" "c'est euh non mais t'as décrit les métadonnées exactement qu'est-ce qu'ils veulent et cetera"
149 1490 "part1" "oui"
150 1500 "part2" "ok c'est juste pour euh pour pour mémoire euh ok donc euh alors après parce que euh peut-être euh si c'est du coup peut-être on on pourrait pour t'aider un peu plus euh illyès peut-être qu'on pourrait essayer de euh de fournir les des données qui seraient plus proche de ce dont tu tu tu as besoin mais ce qui veut dire qu'il faudrait prendre en charge une partie la de de ce ce traitement euh tu dis que tu segmente le fichier de parole de manière semi-automatique avec un avec un un un un outil qui détecte les blancs "
151 1510 "part1" "ouais"
152 1520 "part2" "c'est quoi cet outil c'est toi qui l'as développé ou c'est c'est un outil qui euh du commerce enfin qui est dispo qu'on peut récupérer"
153 1530 "part1" "ouais en fait c'est euh c'est un programme sur matlab c'est euh gratuit on peut l'utiliser"
154 1540 "part2" "ouais enfin matlab c'est pas gratuit"
155 1550 "part1" "ouais"
156 1560 "part2" "peut-être octave peut-être octave"
157 1570 "part1" "matlab matlab c'est pas gratuit "
158 1580 "part2" "non"
159 1590 "part1" "ya octave qui c'est son clone gratuit quoi mais euh y a pas forcement tous le programmes en fait"
160 1600 "part2" "ouais"
161 1610 "part1" "toi c'est matlab ou c'est son euh équivalent euh opensource ou gratuit"
162 1620 "part2" "opensource"
163 1630 "part1" "ouais euh j'utilise matlab "
164 1640 "part2" "matlab oui euh "
165 1650 "part1" "c'est quoi c'est quoi le nom du truc sous matlab que t'utilises"
166 1660 "part2" "euh voicebox il y a d'outil qui permet de voicebox"
167 1670 "part1" "merci"
168 1680 "part2" "y a beaucoup de gens quand même que qu'on voit qui qu'utilises matlab dans ce domaine"
169 1690 "part1" "ben ouais"
170 1700 "part2" "ouais c'est parce que c'est un outil traditionnel "
171 1710 "part1" "pour le traitement du signal ouais ouais "
172 1720 "part2" "ouais c'est c'est "
173 1730 "part1" "parce que le traitement du signal c'est vrai que "
174 1740 "part2" "ouais à l'insa on le laisse tomber euh pour python en ce moment"
175 1750 "part1" "ouais voila la y a python qui est u peu en train de prendre la place mais"
176 1760 "part2" "vous aussi c'est ce que vous utilisiez ouais"
177 1770 "part1" "ouais matlab ouais c'est ce qu'on utilise pour le calcul numérique"
178 1780 "part2" "moi tous mes cours de traitement du signal je crois que c'était sous octave mais"
179 1790 "part1" "sous octave "
180 1800 "part2" "j'ai l'impression qu'il y a un équivalent octave qui existait euh à voicebox"
181 1810 "part1" "j'ai trouvé un truc comme celui la ouais"
182 1820 "part2" "et juste pour euh un petit détail en fait pour la segmentation en fait la segmentation est pertinente pour pour l'extraction du euh de du signal pertinent de de le signal pertinent dont on a besoin parce que si pardon si on a un un un enregistrement de de de de cinquante cinquante minutes ou un truc comme ça avec euh mélangé des gens qui parle et après y a des y a de la musique y a du bruit et cetera si on segmente pas ben donc on a va faire travailler notre système d'apprentissage dans le vide un petit peu en fait donc euh il va prendre il va prendre les moments où y a où y a du vide donc il va travailler la phase d'apprentissage sur celui la mais du coup les résultats ça ça sert à rien on va dire donc euh c'est pas c'est pas optimal donc par contre la segmentation si on passe d'un segment à un autre par exemple d'un premier segment où il y a pas de musique donc voila il le balance il passe au deuxième segment et cetera dès qu'il trouve un signal un signal il commence à à le traiter donc je pense que c'est pour ça qu'à chaque fois c'est ça donne de meilleur résultat donc euh la segmentation nous permet juste en fait de "
183 1830 "part1" "oui mais du coup euh la fréquence enfin non la c'est pas la fréquence la période de dix à quinze secondes c'est peut-être petit non"
184 1840 "part2" "ouais c'est petit mais mais euh ça reste intéressant quand même euh à chaque fois qu'on"
185 1850 "part1" "ouais remarque ouais ça t'évite de "
186 1860 "part2" "voila donc faut pas trop réduire non plus à une seconde  "
187 1870 "part1" "oui oui parce la du coup "
188 1880 "part2" "ça va être ça va donner de meilleur résultat je sais pas mais euh mais euh dix quinze secondes ça paraît plus plutôt raisonnable "
189 1890 "part1" "ben non s'il fait l'apprentissage en voyant jamais de blanc comment il fait pour euh traiter le blanc euh parce qu'il y en a quand on parle tu vois ce que je veux dire"
190 1900 "part2" "tu veux dire euh"
191 1910 "part1" "en vrai en fait "
192 1920 "part2" "ouais si tu segmente euh c'est ce que ce à quoi euh ce à quoi j'ai du mal la c'est si tu segmente les fichiers d'apprentissage ouais  de façon à ce que ce soit entre enfin pas pas parfait mais ce soit vraiment des des moments de parole et t'enlève le blanc ça veut dire euh que ton logiciel la il est jamais confronté à ça  mais quand nous on parle là y a des ya du blanc quoi "
193 1930 "part1" "après bon ça dépend du ça dépend de ça dépend de du modèle "
194 1940 "part2" "ouais"
195 1950 "part1" "parce que kaldi quand on dit des modèles qui utilise le blanc donc euh le blanc parfois il le traduit par noise au départ en premier ou un truc comme ça mais donc entre crochet je l'ai deja essayé quand le micro ne marche pas j'ai fait un enregistrement et j'ai eu des noise noise noise pendant voila"
196 1960 "part2" "d'accord euh c'est deja"
197 1970 "part1" "c'est deja pas le ça dépend du modèle après si ton modèle tu l'as appris euh à faire du blanc en tu lui dis tout ce qu'il le detecte y a pas de soucis ben effectivement alors s'il a pas appris il aura du mal quoi "
198 1980 "part2" "ah ok"
199 1990 "part1" "ouais voila "
200 2000 "part2" "ok donc on pourrait euh peut-être donc il faudrait euh essayer de se rapprocher un peu plus de de ce dont t'as besoin illyès pour euh ouais pour euh pour l'aider "
201 2010 "part1" "ouais "
202 2020 "part2" "euh "
203 2030 "part1" "bon en premier pour en premier lieu on peut tester en utilisant tous les fichier comme ça sans les segmenter pour voir si ça va fonctionner ou non si si euh c'est bon donc on peut on peut terminer comme ça  sinon on doit les segmenter "
204 2040 "part2" "ah tu tu tu penses qu'on peut faire un essai euh "
205 2050 "part1" "ouais"
206 2060 "part2" "un un toute manière on on on recueille le euh le jeu de données "
207 2070 "part1" "ouais "
208 2080 "part2" "on peut peut-être il faudrait essayer peut-être de se donner un un objectif ouais parce que sinon on on est en on on le fait au fur et à mesure et on et puis et puis on sait plus trop ou est-ce qu'on en est donc là euh le le ce qu'on a actuellement c'est trente heures "
209 2090 "part1" "ouais "
210 2100 "part2" "euh on a un modèle pour trente heures donc on pourrait se dire on se donne un modèle pour cent heures ça serait deja deja ça serait deja un coefficient trois et même plus euh euh même si au mille deux cent heures d'aljazira c'est pas beaucoup euh bon c'est peut-etre euh c'est c'est c'est deja un premier un premier step "
211 2110 "part1" "ouais "
212 2120 "part2" "donc sur un modèle alors euh tu toi jessica t'as fait deja des des des euh t'avais deja récupéré des trucs la semaine dernière "
213 2130 "part1" "ah oui j'ai j'ai mis énorme en fait on a un serveur en fait c'est un truc d'illyès sur lequel je dépose plein de fichiers et depuis la semaine dernière j'ai déposé en gros deja deux énormes corpus mais en fait je me rendais pas compte que euh en fait il m'avait dit que qu'il y avait du travail à faire en amont donc je je deposais ça comme ça en fait"
214 2140 "part2" "donc tes deux énormes corpus ils font quelle tu sais quelle taille il font en fin de compte"
215 2150 "part1" "euh je sais en giga après en heures c'est dur parce que les fichiers audio sont pas tous au même endroit mais je dois avoir quatre giga à peu près euh de fichier audio c'est pas les cent les cent et quelques d'aljazira"
216 2160 "part2" "non non mais mais c'est déjà beaucoup  ouais on doit atteindre nos cent heures "
217 2170 "part1" "non pas sur "
218 2180 "part2" "ça dépend "
219 2190 "part1" "faudrait que je je sais pas si "
220 2200 "part2" "quatre giga"
221 2210 "part1" "ça dépend du format des fichiers "
222 2220 "part2" "des fichiers ouais "
223 2230 "part1" "comment on pourrait mesurer ça facilement"
224 2240 "part2" "non mais je crois que je peux voir sur internet "
225 2250 "part1" "en général ils le publient quand ils "
226 2260 "part2" "ouais je vais retrouver le lien des corpus"
227 2270 "part1" ""
228 2280 "part2" "mais c'est vrai que en fait il faudrait peut être un protocole parce que moi depuis une semaine je cherche des corpus et et et fin y a pas vraiment de ouais y a pas d'objectifs enfin Elyès il m'avait pas dit qu'il y avait un traitement à faire après ni rien donc c'est un peu flou quoi"
229 2290 "part1" "ouais tu sais pas trop où tu vas ouais "
230 2300 "part2" "ouais du coup celui là ils le disent pas "
231 2310 "part1" "ah oui ils le disent pas ouais "
232 2320 "part2" "dialogue "
233 2330 "part1" "et celui là "
234 2340 "part2" "en fait vu que c'est plein de fichiers divers et variés et l'autre non ils le disent pas "
235 2350 "part1" "cent vingt quatre mille mots mais c'est tout ça nous aide pas trop "
236 2360 "part2" "bon beh c'est c'est pas grave on va on va le mesurer enfin vous allez je sais pas vous allez regarder voir comment on peut on peut ouais mesurer ça je suppose que peut etre on peut faire au pire on fait une mesure statistique mais ouais on regarde combien combien il y en a"
237 2370 "part1" "ils sont tous à plat dans le même dossier les fichiers audio ou tu es obligée de "
238 2380 "part2" "là à l'heure actuelle sur mon ordi non et sur sur sur le serveur plus "
239 2390 "part1" "donc on se dit on se donne un objectif d'un modèle de cent heures"
240 2400 "part2" "ouais "
241 2410 "part1" "alors ce qui Ilyès ce que tu nous dit c'est que on on pourrait faire un premier essai sans sous échantillon ouvre un terminal sans sous échantillonner "
242 2420 "part2" "ouais "
243 2430 "part1" "sans segmentation"
244 2440 "part2" "sans segmentation"
245 2450 "part1" "donc "
246 2460 "part2" "ffmpeg "
247 2470 "part1" "ffmpeg "
248 2480 "part2" "ffmpeg "
249 2490 "part1" "donc sans un modèle dans un premier temps sans segmentation donc il faut quand même qu'on sâche très précisément qu'est ce que t'as besoin qu'est ce que t'as besoin même si on segmente pas quels sont les formats des fichiers comment doivent être comment doivent être les textes s'il doit être complétement épuré il faut il faudrait "
250 2500 "part2" "c'est quoi le format"
251 2510 "part1" "il faudrait l'épurer etcetera"
252 2520 "part2" "ils donnent pas de durée "
253 2530 "part1" "si tu les tries par type et que tu les ouvres avec VLC est ce qu'il te dit "
254 2540 "part2" "non on verra ça tout a lheure "
255 2550 "part1" "donc est ce qu'on peut est ce qu'on peut deja s'attaquer à cette à cette tache donc de de le mettre en format compatible avec ce dont Ilyès a besoin sans sans segmentation "
256 2560 "part2" "et on dit que ah je sais pas Jessica et Florianne vous vous mettez à ça "
257 2570 "part1" "ouais "
258 2580 "part2" "d'accord"
259 2590 "part1" "et et on essaie aussi d'evaluer le nombre d'heures et et comment et Elyès qui lance l'apprentissage là dessus"
260 2600 "part2" "ok "
261 2610 "part1" "et ensuite apprenti j'imagine que du coup même si on arrive à un truc qui qui avoisine les cent heures ça va nous limer pendant un certain temps pour l'instant parce qu'on a pas de on a rien on a rien il faudrait idéalement il faudrait faire l'apprentissage en mode GMM-HMM et en mode DNN-HMM "
262 2620 "part2" "qu'est ce que t'en penses Ilyès "
263 2630 "part1" "ça nous permettrait de de d'avoir les deux déjà deux deux les deux modèles un GMM et puis un réseau de neurones "
264 2640 "part2" "et ensuite on peut modifier quelque chose et voir la performance combiner par exemple les deux modèles "
